{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\" style=\"color:orange;\"> Linear Algebra </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vector Arithmetic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Given two vectors are :  [1 2 3] [4 5 6]\n",
      "\n",
      "Vector Addition : [1 2 3] + [4 5 6] = [5 7 9]\n",
      "\n",
      "Vector Subtraction : [1 2 3] - [4 5 6] = [-3 -3 -3]\n",
      "\n",
      "Vector Multiplication : [1 2 3] * [4 5 6] = [ 4 10 18]\n",
      "\n",
      "Vector Division : [4 5 6] / [1 2 3] = [4.  2.5 2. ]\n",
      "\n",
      "Vector Dot product : [1 2 3] . [4 5 6] = 32\n",
      "\n",
      "Vector Scalar multiplication : [1 2 3] * 0.5 = [0.5 1.  1.5]\n"
     ]
    }
   ],
   "source": [
    "# vector\n",
    "vector_1 = np.array([1, 2, 3])\n",
    "vector_2 = np.array([4, 5, 6])\n",
    "\n",
    "# add vectors\n",
    "vector_3 = vector_1 +  vector_2\n",
    "\n",
    "# subtract two vectors\n",
    "vector_4 = vector_1 - vector_2\n",
    "\n",
    "# multiply vectors\n",
    "vector_5 = vector_1 * vector_2\n",
    "\n",
    "# divide vector\n",
    "vector_6 = vector_2 / vector_1\n",
    "\n",
    "# vector dot product\n",
    "vector_7 = vector_1.dot(vector_2)\n",
    "\n",
    "# vector scalar multiplication\n",
    "vector_8 = vector_1 * 0.5\n",
    "\n",
    "print(\"Given two vectors are : \", vector_1, vector_2)\n",
    "print(f\"\\nVector Addition : {vector_1} + {vector_2} = {vector_3}\")\n",
    "print(f\"\\nVector Subtraction : {vector_1} - {vector_2} = {vector_4}\")\n",
    "print(f\"\\nVector Multiplication : {vector_1} * {vector_2} = {vector_5}\")\n",
    "print(f\"\\nVector Division : {vector_2} / {vector_1} = {vector_6}\")\n",
    "print(f\"\\nVector Dot product : {vector_1} . {vector_2} = {vector_7}\")\n",
    "print(f\"\\nVector Scalar multiplication : {vector_1} * 0.5 = {vector_8}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vector norms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L1 norm :  28.0\n",
      "L2 norm :  11.832159566199232\n",
      "L max norm :  7.0\n"
     ]
    }
   ],
   "source": [
    "vec_9 = np.array([-1, 2, 3, -4, 5, -6, 7])\n",
    "\n",
    "# norm order parameter = 1\n",
    "l1_norm = np.linalg.norm(vec_9, 1)\n",
    "\n",
    "# norm order = default\n",
    "l2_norm = np.linalg.norm(vec_9)\n",
    "\n",
    "# norm order = inf\n",
    "l_inf_norm = np.linalg.norm(vec_9, float('inf'))\n",
    "\n",
    "print('L1 norm : ', l1_norm)\n",
    "print('L2 norm : ', l2_norm)\n",
    "print('L max norm : ', l_inf_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrix Operations\n",
    "\n",
    "```python\n",
    "# matrix addition\n",
    "def add_matrices(A: list[list[int]], B: list[list[int]]) -> list[list[int]]:\n",
    "    \"\"\"Add two matrices with same dimension\"\"\"\n",
    "    \n",
    "    # Check for valid matrices.\n",
    "    #TODO: This is not exhaustive, complete this\n",
    "    if len(A) != len(B) or len(A[0]) != len(B[0]):\n",
    "        raise ValueError(\"Matrices must have the same dimension\")\n",
    "    \n",
    "    res = [[0 for _ in range(len(A[0]))] for _ in range(len(A))]\n",
    "\n",
    "    # Add corresponding elements\n",
    "    for i in range(len(A)):\n",
    "        for j in range(len(A[0])):\n",
    "            res[i][j] = A[i][j] + B[i][j]\n",
    "    return res\n",
    "```\n",
    "\n",
    "\n",
    "```python\n",
    "# matrix subtraction\n",
    "def subtract_matrices(A: list[list[int]], B: list[list[int]]) -> list[list[int]]:\n",
    "    \"\"\"Subtract two matrices with same dimension\"\"\"\n",
    "    \n",
    "    # Check for valid matrices.\n",
    "\n",
    "    if len(A) != len(B) or len(A[0]) != len(B[0]):\n",
    "        raise ValueError(\"Matrices must have the same dimension\")\n",
    "        \n",
    "    res = [[0 for _ in range(len(A[0]))] for _ in range(len(A))]\n",
    "\n",
    "    # Subtract corresponding elements\n",
    "\n",
    "    for i in range(len(A)):\n",
    "        for j in range(len(A[0])):\n",
    "            res[i][j] = A[i][j] - B[i][j]\n",
    "\n",
    "    return res\n",
    "```\n",
    "\n",
    "```python\n",
    "# matrix multiplication\n",
    "def multiply_matrices(A: list[list[int]], B: list[list[int]]) -> list[list[int]]:\n",
    "    \"\"\"Multiply two matrices\"\"\"\n",
    "    \n",
    "    # Check for valid matrices.\n",
    "\n",
    "    if len(A[0]) != len(B):\n",
    "        raise ValueError(\"Number of columns in A must be equal to number of rows in B\")\n",
    "        \n",
    "    res = [[0 for _ in range(len(B[0]))] for _ in range(len(A))]\n",
    "\n",
    "    # Multiply corresponding elements\n",
    "\n",
    "    for i in range(len(A)):\n",
    "        for j in range(len(B[0])):\n",
    "            for k in range(len(B)):\n",
    "                res[i][j] += A[i][k] * B[k][j]\n",
    "\n",
    "    return res\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A : \n",
      "[[ 1 -2  3 -4]\n",
      " [-9  8 -7  6]\n",
      " [13  0 -7  5]]\n",
      "\n",
      "B : \n",
      "[[ 1  2  3  4]\n",
      " [ 5  6  7  8]\n",
      " [ 9 10 11 12]]\n",
      "\n",
      "A + B = \n",
      "[[ 2  0  6  0]\n",
      " [-4 14  0 14]\n",
      " [22 10  4 17]]\n",
      "\n",
      "A - B = \n",
      "[[  0  -4   0  -8]\n",
      " [-14   2 -14  -2]\n",
      " [  4 -10 -18  -7]]\n",
      "\n",
      "Element-wise matrix multiplication: A o B = \n",
      "[[  1  -4   9 -16]\n",
      " [-45  48 -49  48]\n",
      " [117   0 -77  60]]\n",
      "\n",
      " Matrix F:  [[10 11]\n",
      " [12 13]\n",
      " [14 15]\n",
      " [16 17]]\n",
      "\n",
      "Matrix dot product: A . F = \n",
      "[[-36 -38]\n",
      " [  4   2]\n",
      " [112 123]]\n",
      "\n",
      "A / F = \n",
      "[[ 1.         -1.          1.         -1.        ]\n",
      " [-1.8         1.33333333 -1.          0.75      ]\n",
      " [ 1.44444444  0.         -0.63636364  0.41666667]]\n"
     ]
    }
   ],
   "source": [
    "# Using numpy\n",
    "A = np.array([\n",
    "    [1, -2, 3, -4],\n",
    "    [-9, 8, -7, 6],\n",
    "    [13, 0, -7, 5]\n",
    "])\n",
    "\n",
    "B = np.arange(1, 13).reshape((3, 4))\n",
    "\n",
    "# add two matrices\n",
    "C = A + B\n",
    "\n",
    "# subtract two matrices\n",
    "D = A - B\n",
    "\n",
    "# Hadamard product or element-wise matrix multiplication\n",
    "E = A * B\n",
    "\n",
    "# Matrix - Matrix multiplication or matrix dot product\n",
    "F = np.arange(10, 18).reshape((4, 2))\n",
    "G = A @ F # A.dot(F)\n",
    "\n",
    "# Matrix division\n",
    "H = A / B\n",
    "\n",
    "print(\"A : \", A, \"\\nB : \", B, sep='\\n')\n",
    "print(\"\\nA + B = \", C, sep='\\n')\n",
    "print(\"\\nA - B = \", D, sep='\\n')\n",
    "print(\"\\nElement-wise matrix multiplication: A o B = \", E, sep='\\n')\n",
    "print(\"\\n Matrix F: \", F)\n",
    "print(\"\\nMatrix dot product: A . F = \", G, sep='\\n')\n",
    "print(\"\\nA / F = \", H, sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Properties of Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix J is : \n",
      "[[ 1  2  3  4]\n",
      " [ 5  6  7  8]\n",
      " [ 9 10 11 12]]\n",
      "\n",
      "Transpose of a Matrix J is : \n",
      "[[ 1  5  9]\n",
      " [ 2  6 10]\n",
      " [ 3  7 11]\n",
      " [ 4  8 12]]\n",
      "\n",
      "The matrix K is : \n",
      "[[1 0 1]\n",
      " [0 1 0]\n",
      " [0 0 1]]\n",
      "\n",
      "Inverse of Matrix K is : \n",
      "[[ 1.  0. -1.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  0.  1.]]\n",
      "\n",
      "K . K_inv gives identity matrix : \n",
      "[[1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]]\n",
      "\n",
      "Trace of matrix K is : \n",
      "3\n",
      "\n",
      "Determinant of matrix K is : \n",
      "1.0\n",
      "\n",
      "Rank of matrix K is : \n",
      "3\n",
      "\n",
      "Rank of matrix vector [1 0 1] is:\n",
      "1 \n",
      "\n",
      "Three two dimensional vector with different value ->\n",
      "[[0 0]\n",
      " [0 0]]\n",
      "\n",
      "[[1 2]\n",
      " [1 2]]\n",
      "\n",
      "[[1 2]\n",
      " [3 4]]\n",
      "\n",
      "Rank of L : 0\n",
      "Rank of M : 1\n",
      "Rank of N : 2\n"
     ]
    }
   ],
   "source": [
    "# Transpose of a matrix\n",
    "J = np.arange(1, 13).reshape((3, 4))\n",
    "J_transpose = J.T\n",
    "\n",
    "# Inverse of a matrix\n",
    "K = np.array([\n",
    "    [1, 0, 1],\n",
    "    [0, 1, 0],\n",
    "    [0, 0, 1]])\n",
    "K_inv = np.linalg.inv(K)\n",
    "\n",
    "# trace of a matrix\n",
    "K_trace = np.trace(K)\n",
    "\n",
    "# determinant of a matrix\n",
    "K_det = np.linalg.det(K)\n",
    "\n",
    "# Rank of a matrix\n",
    "K_rank = np.linalg.matrix_rank(K)\n",
    "vector_rank = np.linalg.matrix_rank(K[0])\n",
    "L = np.array([\n",
    "    [0, 0],\n",
    "    [0, 0]\n",
    "])\n",
    "M = np.array([\n",
    "    [1, 2],\n",
    "    [1, 2]\n",
    "])\n",
    "N = np.array([\n",
    "    [1, 2],\n",
    "    [3, 4]\n",
    "])\n",
    "\n",
    "print(\"Matrix J is : \", J, sep='\\n')\n",
    "print(\"\\nTranspose of a Matrix J is : \", J_transpose, sep='\\n')\n",
    "print(\"\\nThe matrix K is : \", K, sep='\\n')\n",
    "print(\"\\nInverse of Matrix K is : \", K_inv, sep='\\n')\n",
    "print(\"\\nK . K_inv gives identity matrix : \", K.dot(K_inv), sep='\\n')\n",
    "print(\"\\nTrace of matrix K is : \", K_trace, sep='\\n')\n",
    "print(\"\\nDeterminant of matrix K is : \", K_det, sep='\\n')\n",
    "print(\"\\nRank of matrix K is : \", K_rank, sep='\\n')\n",
    "print(f\"\\nRank of matrix vector {K[0]} is:\\n{vector_rank} \")\n",
    "print(f\"\\nThree two dimensional vector with different value ->\\n{L}\\n\\n{M}\\n\\n{N}\")\n",
    "print(f\"\\nRank of L : {np.linalg.matrix_rank(L)}\\nRank of M : {np.linalg.matrix_rank(M)}\\nRank of N : {np.linalg.matrix_rank(N)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Types of Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upper Triangular: \n",
      "[[1 2 3]\n",
      " [0 5 6]\n",
      " [0 0 9]]\n",
      "\n",
      "Lower Triangular: \n",
      "[[1 0 0]\n",
      " [4 5 0]\n",
      " [7 8 9]]\n",
      "\n",
      "Diagonal of Matrix I:  [1 5 9]\n",
      "\n",
      "Diagonal Matrix from vector: \n",
      "[[1 0 0]\n",
      " [0 5 0]\n",
      " [0 0 9]]\n",
      "\n",
      "Identity Matrix : \n",
      "[[1 0 0]\n",
      " [0 1 0]\n",
      " [0 0 1]]\n",
      "\n",
      "Orthogonal Matrix : \n",
      "[[ 1  0]\n",
      " [ 0 -1]]\n",
      "\n",
      "Inverse of orthogonal matrix : \n",
      "[[ 1.  0.]\n",
      " [-0. -1.]]\n",
      "\n",
      "Transpose of Orthogonal matrix (equivalent to inverse of orthogonal matrix) : \n",
      "[[ 1  0]\n",
      " [ 0 -1]]\n",
      "\n",
      "Dot product of orthogonal matrix and its transpose (Identity matrix) : \n",
      "[[1 0]\n",
      " [0 1]]\n"
     ]
    }
   ],
   "source": [
    "# triangular upper and lower matrices\n",
    "I = np.arange(1, 10).reshape((3, 3))\n",
    "\n",
    "upper_triangular = np.triu(I)\n",
    "lower_triangular = np.tril(I)\n",
    "\n",
    "# diagonal matrix from vector and extract diagonal from a matrix\n",
    "diagonal_vector = np.diag(I)\n",
    "diagonal_matrix = np.diag(diagonal_vector)\n",
    "\n",
    "# Identity matrix\n",
    "identity_matrix = np.identity(3, dtype=int)\n",
    "\n",
    "# Orthogonal matrix\n",
    "orth_matrix = np.array([\n",
    "    [1, 0],\n",
    "    [0, -1]])\n",
    "inverse_matrix = np.linalg.inv(orth_matrix)\n",
    "\n",
    "print(\"Upper Triangular: \", upper_triangular, sep='\\n')\n",
    "print(\"\\nLower Triangular: \", lower_triangular, sep='\\n')\n",
    "print(\"\\nDiagonal of Matrix I: \", diagonal_vector)\n",
    "print(\"\\nDiagonal Matrix from vector: \", diagonal_matrix, sep='\\n')\n",
    "print(\"\\nIdentity Matrix : \", identity_matrix, sep='\\n')\n",
    "print(\"\\nOrthogonal Matrix : \", orth_matrix, sep='\\n')\n",
    "print(\"\\nInverse of orthogonal matrix : \", inverse_matrix, sep='\\n')\n",
    "print(\"\\nTranspose of Orthogonal matrix (equivalent to inverse of orthogonal matrix) : \", orth_matrix.T, sep='\\n')\n",
    "print(\"\\nDot product of orthogonal matrix and its transpose (Identity matrix) : \", orth_matrix.dot(orth_matrix.T), sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Given matrix P : \n",
      "[[1 0 0 0]\n",
      " [0 1 0 0]\n",
      " [0 0 0 0]\n",
      " [0 0 0 1]]\n",
      "\n",
      "Sparse matrix : \n",
      "<Compressed Sparse Row sparse matrix of dtype 'int64'\n",
      "\twith 3 stored elements and shape (4, 4)>\n",
      "  Coords\tValues\n",
      "  (0, 0)\t1\n",
      "  (1, 1)\t1\n",
      "  (3, 3)\t1\n",
      "\n",
      "Sparse matrix to dense matrix : \n",
      "[[1 0 0 0]\n",
      " [0 1 0 0]\n",
      " [0 0 0 0]\n",
      " [0 0 0 1]]\n",
      "\n",
      "Sparsity score of matrix P :  0.8125 or 81.25 %\n"
     ]
    }
   ],
   "source": [
    "# sparse matrices\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "\n",
    "P = np.array([\n",
    "    [1, 0, 0, 0],\n",
    "    [0, 1, 0, 0],\n",
    "    [0, 0, 0, 0],\n",
    "    [0, 0, 0, 1]\n",
    "])\n",
    "\n",
    "P_sparse = csr_matrix(P)\n",
    "sparsity_score = 1.0 - np.count_nonzero(P) / P.size\n",
    "\n",
    "print(\"Given matrix P : \", P, sep='\\n')\n",
    "print(\"\\nSparse matrix : \", P_sparse, sep='\\n')\n",
    "print(\"\\nSparse matrix to dense matrix : \", P_sparse.todense(), sep='\\n')\n",
    "print(\"\\nSparsity score of matrix P : \", sparsity_score, \"or\", sparsity_score*100, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrix Decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original square matrix A : \n",
      "[[1 2 3]\n",
      " [4 5 6]\n",
      " [7 8 9]]\n",
      "\n",
      "Obtained P, L, and U matrices from LU Decomposition : \n",
      "p :\n",
      "[[0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]] \n",
      "\n",
      "L :\n",
      "[[0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]] \n",
      "\n",
      "U :\n",
      "[[7.         8.         9.        ]\n",
      " [0.         0.85714286 1.71428571]\n",
      " [0.         0.         0.        ]]\n",
      "\n",
      "Reconstructed matrix from P, L, U : \n",
      "[[1. 2. 3.]\n",
      " [4. 5. 6.]\n",
      " [7. 8. 9.]]\n",
      "\n",
      "\n",
      "Original matrix B : \n",
      " [[1 2]\n",
      " [4 5]\n",
      " [8 9]]\n",
      "\n",
      "Q and R matrices obtained from Q R Decomposition : \n",
      "\n",
      "Q : \n",
      "[[-0.11111111 -0.87831549 -0.46499055]\n",
      " [-0.44444444 -0.37457572  0.81373347]\n",
      " [-0.88888889  0.2970773  -0.34874292]]\n",
      "\n",
      "R : \n",
      "[[ -9.         -10.44444444]\n",
      " [  0.          -0.95581392]\n",
      " [  0.           0.        ]]\n",
      "\n",
      "Reconstructed matrix from Q and R : \n",
      " [[1. 2.]\n",
      " [4. 5.]\n",
      " [8. 9.]]\n",
      "\n",
      "\n",
      "Original Matrix A : \n",
      " [[3 2 2]\n",
      " [2 3 2]\n",
      " [2 2 3]]\n",
      "\n",
      "Cholesky matrix : \n",
      " [[1.73205081 0.         0.        ]\n",
      " [1.15470054 1.29099445 0.        ]\n",
      " [1.15470054 0.51639778 1.18321596]]\n",
      "\n",
      "Matrix reconstructed form Cholesky matrix : \n",
      " [[3. 2. 2.]\n",
      " [2. 3. 2.]\n",
      " [2. 2. 3.]]\n",
      "\n",
      "\n",
      "Square Matrix A : \n",
      " [[1 2 3]\n",
      " [4 5 6]\n",
      " [7 8 9]]\n",
      "\n",
      "Eigenvalues :  [ 1.61168440e+01 -1.11684397e+00 -1.30367773e-15]\n",
      "\n",
      "Eigenvectors : \n",
      " [[-0.23197069 -0.78583024  0.40824829]\n",
      " [-0.52532209 -0.08675134 -0.81649658]\n",
      " [-0.8186735   0.61232756  0.40824829]]\n",
      "\n",
      "\n",
      "Reconstruct matrix from eigenvalues and eigenvectors, Inverse of eigen vectors : \n",
      " [[-0.48295226 -0.59340999 -0.70386772]\n",
      " [-0.91788599 -0.24901003  0.41986593]\n",
      " [ 0.40824829 -0.81649658  0.40824829]]\n",
      "\n",
      " Diagonal matrix of eigen values : \n",
      " [[ 1.61168440e+01  0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00 -1.11684397e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00 -1.30367773e-15]]\n",
      "\n",
      "Original matrix reconstructed : \n",
      " [[1. 2. 3.]\n",
      " [4. 5. 6.]\n",
      " [7. 8. 9.]]\n"
     ]
    }
   ],
   "source": [
    "# LU Decomposition\n",
    "from scipy.linalg import lu\n",
    "\n",
    "square_matrix_A = np.arange(1, 10).reshape((3, 3))\n",
    "P_MATRIX, L_MATRIX, U_MATRIX = lu(square_matrix_A)\n",
    "reconstruct_square_matrix_A = P_MATRIX.dot(L_MATRIX).dot(U_MATRIX)\n",
    "\n",
    "# DR Decomposition\n",
    "B_Matrix = np.array([\n",
    "    [1, 2],\n",
    "    [4, 5],\n",
    "    [8, 9]\n",
    "])\n",
    "# adding the 'complete' param will ensure that Q will have size m X m and R will have size m X n\n",
    "Q_matrix, R_matrix = np.linalg.qr(B_Matrix, 'complete')\n",
    "reconstruct_B = Q_matrix @ R_matrix\n",
    "\n",
    "# Cholesky Decomposition\n",
    "square_definite_symmetric_matrix =  np.array([\n",
    "    [3, 2, 2],\n",
    "    [2, 3, 2],\n",
    "    [2, 2, 3]\n",
    "])\n",
    "# upper=True would return the upper triangular matrix; default is False \n",
    "cholesky_matrix = np.linalg.cholesky(square_definite_symmetric_matrix)\n",
    "reconstruct_from_cholesky = cholesky_matrix @ cholesky_matrix.T\n",
    "\n",
    "# Eigendecomposition\n",
    "eigenvalues, eigenvectors = np.linalg.eig(square_matrix_A)\n",
    "# reconstruct matrix\n",
    "inv_eigenvector = np.linalg.inv(eigenvectors)\n",
    "diagonal_matrix_eigenvalues = np.diag(eigenvalues)\n",
    "original_matrix = eigenvectors @ diagonal_matrix_eigenvalues @ inv_eigenvector\n",
    "\n",
    "\n",
    "\n",
    "print(f'Original square matrix A : \\n{square_matrix_A}')\n",
    "print(f'\\nObtained P, L, and U matrices from LU Decomposition : \\np :\\n{P_MATRIX} \\n\\nL :\\n{P_MATRIX} \\n\\nU :\\n{U_MATRIX}')\n",
    "print(f'\\nReconstructed matrix from P, L, U : \\n{reconstruct_square_matrix_A}')\n",
    "\n",
    "print(\"\\n\\nOriginal matrix B : \\n\", B_Matrix)\n",
    "print(\"\\nQ and R matrices obtained from Q R Decomposition : \", \"\\nQ : \", Q_matrix, \"\\nR : \", R_matrix, sep='\\n')\n",
    "print(\"\\nReconstructed matrix from Q and R : \\n\", reconstruct_B)\n",
    "\n",
    "print(\"\\n\\nOriginal Matrix A : \\n\", square_definite_symmetric_matrix)\n",
    "print(\"\\nCholesky matrix : \\n\", cholesky_matrix)\n",
    "print(\"\\nMatrix reconstructed form Cholesky matrix : \\n\", reconstruct_from_cholesky)\n",
    "\n",
    "print(\"\\n\\nSquare Matrix A : \\n\", square_matrix_A)\n",
    "print(\"\\nEigenvalues : \", eigenvalues)\n",
    "print(\"\\nEigenvectors : \\n\", eigenvectors)\n",
    "print(\"\\n\\nReconstruct matrix from eigenvalues and eigenvectors, Inverse of eigen vectors : \\n\", inv_eigenvector)\n",
    "print(\"\\n Diagonal matrix of eigen values : \\n\", diagonal_matrix_eigenvalues)\n",
    "print(\"\\nOriginal matrix reconstructed : \\n\", original_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Given matrix W : \n",
      " [[4 2 6]\n",
      " [5 1 2]\n",
      " [9 1 1]\n",
      " [3 5 7]]\n",
      "\n",
      "U: \n",
      " [[-0.50621566  0.2622625   0.7924518  -0.21675846]\n",
      " [-0.36806485 -0.24457593  0.089958    0.89253484]\n",
      " [-0.53521226 -0.71543254 -0.21323546 -0.39526543]\n",
      " [-0.56729341  0.59963095 -0.56432113 -0.0127505 ]] \n",
      "\n",
      "s: \n",
      " [14.10543944  7.11282752  1.56341387] \n",
      "\n",
      "V: \n",
      " [[-0.7361683  -0.33690375 -0.5869856 ]\n",
      " [-0.67678145  0.36028868  0.64199606]\n",
      " [ 0.00480661 -0.86987811  0.49324332]]\n",
      "\n",
      "\n",
      "Given matrix W: \n",
      " [[4 2 6]\n",
      " [5 1 2]\n",
      " [9 1 1]\n",
      " [3 5 7]]\n",
      "\n",
      "PseudoInverse of W : \n",
      " [[ 0.0039018   0.04275728  0.09535035 -0.02918225]\n",
      " [-0.41554219 -0.05364981  0.09518777  0.35790928]\n",
      " [ 0.29474882  0.0216225  -0.10957568 -0.10030889]]\n",
      "\n",
      "PseudoInverse (without using np.linalg.pinv() function) of W : \n",
      " [[ 0.0039018   0.04275728  0.09535035 -0.02918225]\n",
      " [-0.41554219 -0.05364981  0.09518777  0.35790928]\n",
      " [ 0.29474882  0.0216225  -0.10957568 -0.10030889]]\n"
     ]
    }
   ],
   "source": [
    "# SVD\n",
    "from scipy.linalg import svd\n",
    "\n",
    "\n",
    "W = np.array([\n",
    "    [4, 2, 6],\n",
    "    [5, 1, 2],\n",
    "    [9, 1, 1],\n",
    "    [3, 5, 7]\n",
    "])\n",
    "U, s, V = svd(W)\n",
    "\n",
    "# P.Inv\n",
    "pseudo_inv = np.linalg.pinv(W)\n",
    "\n",
    "# calculating P.Inv without np.linalg.pinv()\n",
    "# Reciprocal of s\n",
    "reciprocal_s = 1.0 / s\n",
    "\n",
    "zero_matrix = np.zeros(W.shape)\n",
    "\n",
    "# s is a vector of singular values of length min(M, N) of W\n",
    "# diagonal matrix of reciprocal_s would be 3 X 3 here.\n",
    "# We replace the first 3 X 3 values of zero matrix with diagonal matrix\n",
    "zero_matrix[0:W.shape[1], 0:W.shape[1]] = np.diag(reciprocal_s)\n",
    "\n",
    "p_inv_new = V.T @ zero_matrix.T @ U.T\n",
    "\n",
    "print(\"Given matrix W : \\n\", W)\n",
    "print(\"\\nU: \\n\", U, \"\\n\\ns: \\n\", s, \"\\n\\nV: \\n\", V)\n",
    "print(\"\\n\\nGiven matrix W: \\n\", W)\n",
    "print(\"\\nPseudoInverse of W : \\n\", pseudo_inv)\n",
    "print(\"\\nPseudoInverse (without using np.linalg.pinv() function) of W : \\n\", p_inv_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensors & Tensor Arithmetic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Depth-Row-Col (3, 2, 4)\n",
      "\n",
      "3D Tensor : \n",
      " [[[1 2 3 4]\n",
      "  [0 9 8 8]]\n",
      "\n",
      " [[4 5 6 7]\n",
      "  [1 0 9 4]]\n",
      "\n",
      " [[1 9 4 5]\n",
      "  [2 5 6 8]]]\n"
     ]
    }
   ],
   "source": [
    "T1 = np.array([\n",
    "    [[1, 2, 3, 4], [0, 9, 8, 8]],\n",
    "    [[4, 5, 6, 7], [1, 0, 9, 4]],\n",
    "    [[1, 9, 4, 5], [2, 5, 6, 8]]\n",
    "])\n",
    "\n",
    "print(\"Depth-Row-Col\", T1.shape)\n",
    "print(\"\\n3D Tensor : \\n\", T1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor T1 : \n",
      " [[[1 2 3 4]\n",
      "  [0 9 8 8]]\n",
      "\n",
      " [[4 5 6 7]\n",
      "  [1 0 9 4]]\n",
      "\n",
      " [[1 9 4 5]\n",
      "  [2 5 6 8]]]\n",
      "\n",
      "Tensor T2 : \n",
      " [[[ 1  2  3  4]\n",
      "  [ 5  6  7  8]]\n",
      "\n",
      " [[ 9 10 11 12]\n",
      "  [13 14 15 16]]\n",
      "\n",
      " [[17 18 19 20]\n",
      "  [21 22 23 24]]]\n",
      "\n",
      "Adding tensors T1 and T2 : \n",
      " [[[ 2  4  6  8]\n",
      "  [ 5 15 15 16]]\n",
      "\n",
      " [[13 15 17 19]\n",
      "  [14 14 24 20]]\n",
      "\n",
      " [[18 27 23 25]\n",
      "  [23 27 29 32]]]\n",
      "\n",
      "Subtracting tensors T2 from T3 : \n",
      " [[[1 2 3 4]\n",
      "  [0 9 8 8]]\n",
      "\n",
      " [[4 5 6 7]\n",
      "  [1 0 9 4]]\n",
      "\n",
      " [[1 9 4 5]\n",
      "  [2 5 6 8]]]\n",
      "\n",
      "Multiplying tensors T1 from T2 : \n",
      " [[[  1   4   9  16]\n",
      "  [  0  54  56  64]]\n",
      "\n",
      " [[ 36  50  66  84]\n",
      "  [ 13   0 135  64]]\n",
      "\n",
      " [[ 17 162  76 100]\n",
      "  [ 42 110 138 192]]]\n",
      "\n",
      "Dividing tensors T2 from T3 : \n",
      " [[[2.         2.         2.         2.        ]\n",
      "  [1.         2.5        2.14285714 2.        ]]\n",
      "\n",
      " [[1.44444444 1.5        1.54545455 1.58333333]\n",
      "  [1.07692308 1.         1.6        1.25      ]]\n",
      "\n",
      " [[1.05882353 1.5        1.21052632 1.25      ]\n",
      "  [1.0952381  1.22727273 1.26086957 1.33333333]]]\n",
      "\n",
      "Tensor dot product of T1 and T7 : \n",
      " [[[[[ 1  2  3  4]\n",
      "    [ 0  9  8  8]]\n",
      "\n",
      "   [[ 4  5  6  7]\n",
      "    [ 1  0  9  4]]\n",
      "\n",
      "   [[ 1  9  4  5]\n",
      "    [ 2  5  6  8]]]\n",
      "\n",
      "\n",
      "  [[[ 2  4  6  8]\n",
      "    [ 0 18 16 16]]\n",
      "\n",
      "   [[ 8 10 12 14]\n",
      "    [ 2  0 18  8]]\n",
      "\n",
      "   [[ 2 18  8 10]\n",
      "    [ 4 10 12 16]]]\n",
      "\n",
      "\n",
      "  [[[ 3  6  9 12]\n",
      "    [ 0 27 24 24]]\n",
      "\n",
      "   [[12 15 18 21]\n",
      "    [ 3  0 27 12]]\n",
      "\n",
      "   [[ 3 27 12 15]\n",
      "    [ 6 15 18 24]]]]] \n",
      " Dimension of tensor dot product is :  (1, 3, 3, 2, 4)\n"
     ]
    }
   ],
   "source": [
    "T2 = np.arange(1, 25).reshape((3, 2, 4))\n",
    "\n",
    "# Tensor addition\n",
    "T3 = T1 +  T2\n",
    "\n",
    "# Tensor subtraction\n",
    "T4 = T3 - T2\n",
    "\n",
    "# Tensor multiplication (Hadamard product)\n",
    "T5 = T1 * T2\n",
    "\n",
    "# Tensor division\n",
    "T6 = T3 / T2\n",
    "\n",
    "# Tensor dot product\n",
    "T7 = np.array([\n",
    "    [1, 2, 3]\n",
    "])\n",
    "\n",
    "T8 = np.tensordot(T7, T1, axes=0)\n",
    "\n",
    "print(\"Tensor T1 : \\n\", T1)\n",
    "print(\"\\nTensor T2 : \\n\", T2)\n",
    "print(\"\\nAdding tensors T1 and T2 : \\n\", T3)\n",
    "print(\"\\nSubtracting tensors T2 from T3 : \\n\", T4)\n",
    "print(\"\\nMultiplying tensors T1 from T2 : \\n\", T5)\n",
    "print(\"\\nDividing tensors T2 from T3 : \\n\", T6)\n",
    "print(\"\\nTensor dot product of T1 and T7 : \\n\", T8, \"\\n Dimension of tensor dot product is : \", T8.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Reduction using SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a 5 X 25 matrix\n",
    "data_matrix = np.arange(1, 126).reshape((5, 25))\n",
    "\n",
    "# SVD\n",
    "U, s, V = svd(data_matrix)\n",
    "\n",
    "# m X n Sigma matrix\n",
    "sigma = np.zeros(data_matrix.shape)\n",
    "\n",
    "# populate sigma with n X n diagonal matrix\n",
    "sigma[:data_matrix.shape[0], :data_matrix.shape[0]] = np.diag(s)\n",
    "\n",
    "ELEMENTS = 3\n",
    "# sigma[Row, Col]\n",
    "sigma = sigma[:, 0:ELEMENTS]\n",
    "V = V[:ELEMENTS, :]\n",
    "\n",
    "# Reconstruct\n",
    "reconstruct_data_matrix = U @ sigma @ V\n",
    "\n",
    "# transform\n",
    "transform1 = U @ sigma\n",
    "transform2 = data_matrix @ V.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data matrix : \n",
      "[[  1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17  18\n",
      "   19  20  21  22  23  24  25]\n",
      " [ 26  27  28  29  30  31  32  33  34  35  36  37  38  39  40  41  42  43\n",
      "   44  45  46  47  48  49  50]\n",
      " [ 51  52  53  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68\n",
      "   69  70  71  72  73  74  75]\n",
      " [ 76  77  78  79  80  81  82  83  84  85  86  87  88  89  90  91  92  93\n",
      "   94  95  96  97  98  99 100]\n",
      " [101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118\n",
      "  119 120 121 122 123 124 125]]\n",
      "\n",
      "\n",
      "Reconstruct Data matrix : \n",
      "[[  1.   2.   3.   4.   5.   6.   7.   8.   9.  10.  11.  12.  13.  14.\n",
      "   15.  16.  17.  18.  19.  20.  21.  22.  23.  24.  25.]\n",
      " [ 26.  27.  28.  29.  30.  31.  32.  33.  34.  35.  36.  37.  38.  39.\n",
      "   40.  41.  42.  43.  44.  45.  46.  47.  48.  49.  50.]\n",
      " [ 51.  52.  53.  54.  55.  56.  57.  58.  59.  60.  61.  62.  63.  64.\n",
      "   65.  66.  67.  68.  69.  70.  71.  72.  73.  74.  75.]\n",
      " [ 76.  77.  78.  79.  80.  81.  82.  83.  84.  85.  86.  87.  88.  89.\n",
      "   90.  91.  92.  93.  94.  95.  96.  97.  98.  99. 100.]\n",
      " [101. 102. 103. 104. 105. 106. 107. 108. 109. 110. 111. 112. 113. 114.\n",
      "  115. 116. 117. 118. 119. 120. 121. 122. 123. 124. 125.]]\n",
      "\n",
      "\n",
      "T1 : \n",
      "[[-6.78880492e+01 -3.02690068e+01  8.88740499e-15]\n",
      " [-1.92414922e+02 -1.94035547e+01 -5.79859834e-15]\n",
      " [-3.16941794e+02 -8.53810255e+00  1.57714031e-14]\n",
      " [-4.41468666e+02  2.32734957e+00 -4.96966311e-14]\n",
      " [-5.65995539e+02  1.31928017e+01  3.08364214e-14]]\n",
      "\n",
      "\n",
      "T2 : \n",
      "[[-6.78880492e+01 -3.02690068e+01  1.99840144e-15]\n",
      " [-1.92414922e+02 -1.94035547e+01 -1.02140518e-14]\n",
      " [-3.16941794e+02 -8.53810255e+00 -3.39728246e-14]\n",
      " [-4.41468666e+02  2.32734957e+00 -3.81916720e-14]\n",
      " [-5.65995539e+02  1.31928017e+01 -4.77395901e-14]]\n"
     ]
    }
   ],
   "source": [
    "print(f\"Data matrix : \\n{data_matrix}\")\n",
    "print(f\"\\n\\nReconstruct Data matrix : \\n{reconstruct_data_matrix}\")\n",
    "print(f\"\\n\\nT1 : \\n{transform1}\")\n",
    "print(f\"\\n\\nT2 : \\n{transform2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 6.78880492e+01 -3.02690068e+01  7.77156117e-16]\n",
      " [ 1.92414922e+02 -1.94035547e+01  3.33066907e-15]\n",
      " [ 3.16941794e+02 -8.53810255e+00  5.55111512e-16]\n",
      " [ 4.41468666e+02  2.32734957e+00  1.37667655e-14]\n",
      " [ 5.65995539e+02  1.31928017e+01  1.98729921e-14]]\n"
     ]
    }
   ],
   "source": [
    "# Scikit learn has this builtin\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "\n",
    "trunc_svd = TruncatedSVD(n_components=3)\n",
    "\n",
    "trunc_svd.fit(data_matrix)\n",
    "out = trunc_svd.transform(data_matrix)\n",
    "\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some sign inconsistencies are expected between the sklearn version and our implementation. This is fine as long as we train and reuse the model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (base-env)",
   "language": "python",
   "name": "base-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
